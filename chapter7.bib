@book{pena2008self,
  title={Self-normalized processes: Limit theory and Statistical Applications},
  author={Pe{\~n}a, Victor H and Lai, Tze Leung and Shao, Qi-Man},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@Article{Lu1997,
	author={Lu, Xiao-Yun
	and Spurgeon, Sarah K.},
	title={Robust sliding mode control of uncertain nonlinear systems},
	journal={Systems {\&} Control Letters},
	year={1997},
	month={Nov},
	day={03},
	volume={32},
	number={2},
	pages={75-90},
	keywords={Robustness; Sliding mode control; Dynamic feedback; Zero dynamics; Uniform ultimate boundedness},
	abstract={A dynamic sliding mode controller design method is proposed for multiple input-output systems with additive uncertainties. A previous result on the stability of triangular systems is generalised to the case of uniform ultimate boundedness of controlled triangular systems. This is used to prove the stability of the overall closed-loop system. The uncertain system with appropriately chosen sliding mode control is shown to be ultimately bounded if the zero dynamics of the nominal system are uniformly asymptotically (exponentially) stable. The design method is demonstrated with two examples.},
	issn={0167-6911},
}


@article{Sastry1990,
	abstract = {This volume surveys the major results and techniques of analysis in the field of adaptive control. Focusing on linear, continuous time, single-input, single-output systems, the authors offer a clear, conceptual presentation of adaptive methods, enabling a critical evaluation of these techniques and suggesting avenues of further development.},
	author = {Sastry, Shankar and Bodson, Marc and Bartram, James F.},
	doi = {10.1121/1.399905},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	title = {{Adaptive Control: Stability, Convergence, and Robustness}},
	year = {1990}
}

@article{Tanaskovic2014,
	abstract = {An adaptive control algorithm for open-loop stable, constrained, linear, multiple input multiple output systems is presented. The proposed approach can deal with both input and output constraints, as well as measurement noise and output disturbances. The adaptive controller consists of an iterative set membership identification algorithm, that provides a set of candidate plant models at each time step, and a model predictive controller, that enforces input and output constraints for all the plants inside the model set. The algorithm relies only on the solution of standard convex optimization problems that are guaranteed to be recursively feasible. The experimental results obtained by applying the proposed controller to a quad-tank testbed are presented.},
	author = {Tanaskovic, Marko and Fagiano, Lorenzo and Smith, Roy and Morari, Manfred},
	doi = {10.1016/j.automatica.2014.10.036},
	issn = {00051098},
	journal = {Automatica},
	keywords = {Adaptive control,Control of constrained systems,Impulse response,Learning control,Model predictive control,Self tuning control,Set membership identification},
	title = {{Adaptive receding horizon control for constrained MIMO systems}},
	year = {2014}
}

@inproceedings{Amos2018,
	abstract = {We present foundations for using Model Predictive Control (MPC) as a differentiable policy class for reinforcement learning in continuous state and action spaces. This provides one way of leveraging and combining the advantages of model-free and model-based approaches. Specifically, we differentiate through MPC by using the KKT conditions of the convex approximation at a fixed point of the controller. Using this strategy, we are able to learn the cost and dynamics of a controller via end-to-end learning. Our experiments focus on imitation learning in the pendulum and cartpole domains, where we learn the cost and dynamics terms of an MPC policy class. We show that our MPC policies are significantly more data-efficient than a generic neural network and that our method is superior to traditional system identification in a setting where the expert is unrealizable.},
	archivePrefix = {arXiv},
	arxivId = {1810.13400},
	author = {Amos, Brandon and Rodriguez, Ivan Dario Jimenez and Sacks, Jacob and Boots, Byron and {Zico Kolter}, J.},
	booktitle = {Advances in Neural Information Processing Systems},
	eprint = {1810.13400},
	issn = {10495258},
	title = {{Differentiable MPC for end-to-end planning and control}},
	year = {2018}
}

@ARTICLE{Doyle1978,
	author={J. {Doyle}},
	journal={IEEE Transactions on Automatic Control}, 
	title={Guaranteed margins for LQG regulators}, 
	year={1978},
	volume={23},
	number={4},	
	pages={756-757},
}


@article{Efimov2013,
  author = {Efimov, D. and Ra\"issi, T. and Chebotarev, S. and Zolghadri, A.},
  title = {Interval State Observer for Nonlinear Time Varying Systems},
  journal = {Automatica},
  year = {2013},
  volume = {49},
  pages = {200--205},
  number = {1},
  owner = {EfDe},
  timestamp = {2013.01.08}
}

@unpublished{maillard2016,
  TITLE = {{Self-normalization techniques for streaming confident regression}},
  AUTHOR = {Maillard, Odalric-Ambrym},
  URL = {https://hal.archives-ouvertes.fr/hal-01349727},
  NOTE = {working paper or preprint},
  YEAR = {2016},
  MONTH = May,
  KEYWORDS = {regression ; dependent variables ; Concentration inequalities ; self-normalized ; sequential prediction},
  HAL_ID = {hal-01349727},
  HAL_VERSION = {v1},
}

@incollection{Abbasi2011,
title = {Improved Algorithms for Linear Stochastic Bandits},
author = {Yasin Abbasi-yadkori and P\'{a}l, D\'{a}vid and Csaba Szepesv\'{a}ri},
booktitle = {Advances in Neural Information Processing Systems 24},
editor = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
pages = {2312--2320},
year = {2011},
publisher = {Curran Associates, Inc.},
}



@InProceedings{abbasi-yadkori11a,
  title = 	 {Regret Bounds for the Adaptive Control of Linear Quadratic Systems},
  author = 	 {Yasin Abbasi-Yadkori and Csaba Szepesvári},
  booktitle = 	 {Proceedings of the 24th Annual Conference on Learning Theory},
  pages = 	 {1--26},
  year = 	 {2011},
  editor = 	 {Sham M. Kakade and Ulrike von Luxburg},
  volume = 	 {19},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Budapest, Hungary},
  month = 	 {09--11 Jun},
  publisher = 	 {PMLR},
}

@InProceedings{abeille18a,
  title = 	 {Improved Regret Bounds for Thompson Sampling in Linear Quadratic Control Problems},
  author = 	 {Abeille, Marc and Lazaric, Alessandro},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1--9},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  abstract = 	 {Thompson sampling (TS) is an effective approach to trade off exploration and exploration in reinforcement learning. Despite its empirical success and recent advances, its theoretical analysis is often limited to the Bayesian setting, finite state-action spaces, or finite-horizon problems. In this paper, we study an instance of TS in the challenging setting of the infinite-horizon linear quadratic (LQ) control, which models problems with continuous state-action variables, linear dynamics, and quadratic cost. In particular, we analyze the regret in the frequentist sense (i.e., for a fixed unknown environment) in one-dimensional systems. We derive the first $O(\sqrt{T})$ frequentist regret bound for this problem, thus significantly improving the $O(T^{2/3})$ bound of Abeille & Lazaric (2017) and matching the frequentist performance derived by Abbasi-Yadkori & Szepesvári (2011) for an optimistic approach and the Bayesian result Ouyang et al. (2017) We obtain this result by developing a novel bound on the regret due to policy switches, which holds for LQ systems of any dimensionality and it allows updating the parameters and the policy at each step, thus overcoming previous limitations due to lazy updates. Finally, we report numerical simulations supporting the conjecture that our result extends to multi-dimensional systems.}
}

@article{Dean2017,
  title={On the Sample Complexity of the Linear Quadratic Regulator},
  author={Sarah Dean and Horia Mania and Nikolai Matni and Benjamin Recht and Stephen Tu},
  journal={ArXiv},
  year={2017},
  volume={abs/1710.01688}
}

@incollection{Dean2018,
title = {Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator},
author = {Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {4188--4197},
year = {2018},
publisher = {Curran Associates, Inc.},
}


@inproceedings{kirschner18heteroscedastic,
	Author = {Johannes Kirschner and Andreas Krause},
	Booktitle = {Proc. International Conference on Learning Theory (COLT)},
	Month = {July},
	Title = {Information Directed Sampling and Bandits with Heteroscedastic Noise},
	Year = {2018}}
	
@unpublished{maillard:hal-01349727,
  TITLE = {{Self-normalization techniques for streaming confident regression}},
  AUTHOR = {Maillard, Odalric-Ambrym},
  URL = {https://hal.archives-ouvertes.fr/hal-01349727},
  NOTE = {working paper or preprint},
  YEAR = {2016},
  MONTH = May,
  KEYWORDS = {regression ; dependent variables ; Concentration inequalities ; sequential prediction ; self-normalized},
  PDF = {https://hal.archives-ouvertes.fr/hal-01349727/file/HalSubmittedV2.pdf},
  HAL_ID = {hal-01349727},
  HAL_VERSION = {v2},
}

@article{Schneider1997,
author = {Schneider, JG},
journal = {Advances in neural information processing systems},
pages = {1047----1053},
title = {{Exploiting model uncertainty estimates for safe dynamic control learning}},
year = {1997}
}

@article{delos2015,
  TITLE = {{Minkowski Sum of Polytopes Defined by Their Vertices}},
  AUTHOR = {Delos, Vincent and Teissandier, Denis},
  JOURNAL = {{Journal of Applied Mathematics and Physics (JAMP)}},
  VOLUME = {3},
  NUMBER = {1},
  PAGES = {62-67},
  YEAR = {2015},
  MONTH = Jan,
}

@article {Silver1140,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	publisher = {American Association for the Advancement of Science},
	journal = {Science}
}

@article{mnih2015humanlevel,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	journal = {Nature},
	month = feb,
	number = 7540,
	pages = {529--533},
	publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	title = {Human-level control through deep reinforcement learning},
	volume = 518,
	year = 2015
}

@article{Basar1996,
abstract = {In this work, the authors present a complete theory that encompasses continuous-time as well as discrete-time systems, finite as well as infinite horizons, and several different measurement schemes. They also discuss extensions of the linear theory to nonlinear systems. One of the major concentrated activities of the past decade in control theory has been the development of the so-called "H-infinity-optimal control theory", which addresses the issue of worst-case controller design for linear plants subject to unknown disturbances and plant uncertainties. Among the different time-domain approaches to this class of worst-case design problems, the one that uses the framework of dynamic, differential game theory stands out to be the most natural. This is so because the original H-infinity control problem (in its equivalent time-domain formulation) is in fact a minimax optimization problem, and hence a zero-sum game, where the controller can be viewed as the minimizing player and disturbance as the maximizing player. Using this framework, the authors present in this book a complete theory that encompasses continuous-time as well as discrete-time systems, finite as well as infinite horizons, and several different measurement schemes, including closed loop perfect state, delayed perfect state, samples state, closed-loop imperfect state, delayed imperfect state and sampled imperfect state information patterns. They also discuss extensions of the linear theory to nonlinear systems, and derivation of the lower dimensional controller for systems with regularly and singularly perturbed dynamics. This is the second edition of a 1991 book with the same title, which, besides featuring a more streamlined presentation of the results included in the first edition, and at places under more refined conditions, also contains substantial new material, reflecting new developments in the field since 1991. Among these are the nonlinear theory; connections between H-infinity-optimal control and risk sensitive stochastic control problems; H-infinity filtering for linear and nonlinear systems; and robustness considerations in the presence of regular and singular perturbations. Also included are a rather detailed description of the relationship between frequency-and time-domain approaches to robust controller design, and a complete set of results on the existence of value and characterization of optimal policies in finite- and infinite-horizon LQ differential games. The authors believe that the theory is now at a stage where it can easily be incorporated into a second-level graduate course in a control curriculum, that would follow a basic course in linear control theory covering LQ and LQG designs. The framework adopted in this book makes such an ambitious plan possible. For the most part, the only prerequisite for the book is a basic knowledge of linear control theory. No background in differential games, or game theory in general, is required, as the requisite concepts and results have been developed in the book at the appropriate level. The book is written in such a way that makes it possible to follow the theory for the continuous- and discrete-time systems independently (and also in parallel).},
author = {Basar, T. and Bernhard, P.},
doi = {10.1109/tac.1996.536519},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
title = {{H-infinity Optimal Control and Related Minimax Design Problems: A Dynamic Game Approach}},
year = {1996}
}


@inproceedings{Mansley2011,
	author = {Mansley, Chris and Weinstein, Ari and Littman, Michael},
	year = {2011},
	month = {01},
	title = {Sample-Based Planning for Continuous Action Markov Decision Processes.},
	journal = {Proceedings of the 21st International Conference on Automated Planning and Scheduling}
}

@article{Weinstein2012,
	author = {Weinstein, A. and Littman, M.L.},
	year = {2012},
	month = {01},
	pages = {306-314},
	title = {Bandit-based planning and learning in continuous-action markov decision processes},
	journal = {Proceedings of the 22nd International Conference on Automated Planning and Scheduling}
}

@ARTICLE{Efimov2012,
	author = {Efimov, D. and Fridman, L.M. and Ra\"issi, T. and Zolghadri, A. and
	Seydou, R.},
	title = {Interval Estimation for {LPV} Systems Applying High Order Sliding
	Mode Techniques},
	journal = {Automatica},
	year = {2012},
	volume = {48},
	pages = {2365--2371},
}

@article{Kumar2013,
	title = {Robust LQR Controller Design for Stabilizing and Trajectory Tracking of Inverted Pendulum},
	journal = {Procedia Engineering},
	volume = {64},
	pages = {169 - 178},
	year = {2013},
	note = {International Conference on Design and Manufacturing},
	author = {E. Vinodh Kumar and Jovitha Jerome}
}

@inproceedings{Lenz2015,
	title={DeepMPC: Learning Deep Latent Features for Model Predictive Control},
	author={Ian Lenz and Ross A. Knepper and Ashutosh Saxena},
	booktitle={Robotics: Science and Systems},
	year={2015}
}

@article{Levine2015,
	author    = {Sergey Levine and
	Chelsea Finn and
	Trevor Darrell and
	Pieter Abbeel},
	title     = {End-to-End Training of Deep Visuomotor Policies},
	journal   = {CoRR},
	volume    = {abs/1504.00702},
	year      = {2015},
	archivePrefix = {arXiv},
	eprint    = {1504.00702}
}

@book{Bental2009,
	title={Robust optimization},
	author={Ben-Tal, Aharon and El Ghaoui, Laurent and Nemirovski, Arkadi},
	volume={28},
	year={2009},
	publisher={Princeton University Press}
}
@article{Bertsimas2011,
	title={Theory and applications of robust optimization},
	author={Bertsimas, Dimitris and Brown, David B and Caramanis, Constantine},
	journal={SIAM review},
	volume={53},
	number={3},
	pages={464--501},
	year={2011},
	publisher={SIAM}
}

@article{Gorissen2015,
	title = {A practical guide to robust optimization},
	journal = {Omega},
	volume = {53},
	pages = {124 - 137},
	year = {2015},
	author = {Bram L. Gorissen and İhsan Yanıkoğlu and Dick den Hertog},
}

@phdthesis{le2012,
	TITLE = {Robust predictive control by zonotopic set-membership estimation.},
	AUTHOR = {Le, Vu Tuan Hieu},
	NUMBER = {2012SUPL0016},
	SCHOOL = {{Sup{\'e}lec}},
	YEAR = {2012},
	MONTH = Oct,
	KEYWORDS = {Uncertain system ; Model predictive control ; Set-membership estimation ; Syst{\`e}me incertain ; Estimation ensembliste ; Zonotope ; Commande pr{\'e}dictive},
	TYPE = {Theses}
}

@article{Ibrahimi2013,
	author = {Ibrahimi, Morteza and Javanmard, Adel and Roy, Benjamin},
	year = {2013},
	month = {03},
	title = {Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems},
	volume = {4},
	journal = {Advances in Neural Information Processing Systems}
}

@article{Faradonbeh2017,
	author    = {Mohamad Kazem Shirani Faradonbeh and Ambuj Tewari and George Michailidis},
	title     = {Finite Time Analysis of Optimal Adaptive Policies for Linear-Quadratic
	Systems},
	journal   = {CoRR},
	volume    = {abs/1711.07230},
	year      = {2017},
	archivePrefix = {arXiv},
	eprint    = {1711.07230},
}

@article{Ouyang2017,
	author    = {Yi Ouyang and
	Mukul Gagrani and
	Rahul Jain},
	title     = {Learning-based Control of Unknown Linear Systems with Thompson Sampling},
	journal   = {CoRR},
	volume    = {abs/1709.04047},
	year      = {2017},
	archivePrefix = {arXiv},
	eprint    = {1709.04047},
}