@book{pena2008self,
  title={Self-normalized processes: Limit theory and Statistical Applications},
  author={Pe{\~n}a, Victor H and Lai, Tze Leung and Shao, Qi-Man},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@Article{Lu1997,
	author={Lu, Xiao-Yun
	and Spurgeon, Sarah K.},
	title={Robust sliding mode control of uncertain nonlinear systems},
	journal={Systems {\&} Control Letters},
	year={1997},
	month={Nov},
	day={03},
	volume={32},
	number={2},
	pages={75-90},
	keywords={Robustness; Sliding mode control; Dynamic feedback; Zero dynamics; Uniform ultimate boundedness},
	abstract={A dynamic sliding mode controller design method is proposed for multiple input-output systems with additive uncertainties. A previous result on the stability of triangular systems is generalised to the case of uniform ultimate boundedness of controlled triangular systems. This is used to prove the stability of the overall closed-loop system. The uncertain system with appropriately chosen sliding mode control is shown to be ultimately bounded if the zero dynamics of the nominal system are uniformly asymptotically (exponentially) stable. The design method is demonstrated with two examples.},
	issn={0167-6911},
}

@article{Sastry1990,
	author = {Sastry,Shankar  and Bodson,Marc  and Bartram,James F. },
	title = {Adaptive Control: Stability, Convergence, and Robustness},
	journal = {The Journal of the Acoustical Society of America},
	volume = {88},
	number = {1},
	pages = {588-589},
	year = {1990},
	doi = {10.1121/1.399905},
}

@article{Tanaskovic2014,
	title = "Adaptive receding horizon control for constrained MIMO systems",
	journal = "Automatica",
	volume = "50",
	number = "12",
	pages = "3019 - 3029",
	year = "2014",
	issn = "0005-1098",
	doi = "https://doi.org/10.1016/j.automatica.2014.10.036",
	url = "http://www.sciencedirect.com/science/article/pii/S0005109814004178",
	author = "Marko Tanaskovic and Lorenzo Fagiano and Roy Smith and Manfred Morari",
	keywords = "Adaptive control, Self tuning control, Learning control, Set membership identification, Model predictive control, Control of constrained systems, Impulse response",
	abstract = "An adaptive control algorithm for open-loop stable, constrained, linear, multiple input multiple output systems is presented. The proposed approach can deal with both input and output constraints, as well as measurement noise and output disturbances. The adaptive controller consists of an iterative set membership identification algorithm, that provides a set of candidate plant models at each time step, and a model predictive controller, that enforces input and output constraints for all the plants inside the model set. The algorithm relies only on the solution of standard convex optimization problems that are guaranteed to be recursively feasible. The experimental results obtained by applying the proposed controller to a quad-tank testbed are presented."
}

@incollection{Amos2018,
	title = {Differentiable MPC for End-to-end Planning and Control},
	author = {Amos, Brandon and Jimenez, Ivan and Sacks, Jacob and Boots, Byron and Kolter, J. Zico},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {8289--8300},
	year = {2018},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/8050-differentiable-mpc-for-end-to-end-planning-and-control.pdf}
}

@ARTICLE{Doyle1978,
	author={J. {Doyle}},
	journal={IEEE Transactions on Automatic Control}, 
	title={Guaranteed margins for {LQG} regulators}, 
	year={1978},
	volume={23},
	number={4},	
	pages={756-757},
}


@article{Efimov2013,
  author = {Efimov, D. and Ra\"issi, T. and Chebotarev, S. and Zolghadri, A.},
  title = {Interval State Observer for Nonlinear Time Varying Systems},
  journal = {Automatica},
  year = {2013},
  volume = {49},
  pages = {200--205},
  number = {1},
  owner = {EfDe},
  timestamp = {2013.01.08}
}

@unpublished{maillard2016,
  TITLE = {{Self-normalization techniques for streaming confident regression}},
  AUTHOR = {Maillard, Odalric-Ambrym},
  URL = {https://hal.archives-ouvertes.fr/hal-01349727},
  NOTE = {working paper or preprint},
  YEAR = {2016},
  MONTH = May,
  KEYWORDS = {regression ; dependent variables ; Concentration inequalities ; self-normalized ; sequential prediction},
  HAL_ID = {hal-01349727},
  HAL_VERSION = {v1},
}

@incollection{Abbasi2011,
title = {Improved Algorithms for Linear Stochastic Bandits},
author = {Yasin Abbasi-yadkori and P\'{a}l, D\'{a}vid and Csaba Szepesv\'{a}ri},
booktitle = {Advances in Neural Information Processing Systems 24},
editor = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
pages = {2312--2320},
year = {2011},
publisher = {Curran Associates, Inc.},
}



@InProceedings{abbasi-yadkori11a,
  title = 	 {Regret Bounds for the Adaptive Control of Linear Quadratic Systems},
  author = 	 {Yasin Abbasi-Yadkori and Csaba Szepesvári},
  booktitle = 	 {Proceedings of the 24th Annual Conference on Learning Theory},
  pages = 	 {1--26},
  year = 	 {2011},
  editor = 	 {Sham M. Kakade and Ulrike von Luxburg},
  volume = 	 {19},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Budapest, Hungary},
  month = 	 {09--11 Jun},
  publisher = 	 {PMLR},
}

@InProceedings{abeille18a,
  title = 	 {Improved Regret Bounds for Thompson Sampling in Linear Quadratic Control Problems},
  author = 	 {Abeille, Marc and Lazaric, Alessandro},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1--9},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  abstract = 	 {Thompson sampling (TS) is an effective approach to trade off exploration and exploration in reinforcement learning. Despite its empirical success and recent advances, its theoretical analysis is often limited to the Bayesian setting, finite state-action spaces, or finite-horizon problems. In this paper, we study an instance of TS in the challenging setting of the infinite-horizon linear quadratic (LQ) control, which models problems with continuous state-action variables, linear dynamics, and quadratic cost. In particular, we analyze the regret in the frequentist sense (i.e., for a fixed unknown environment) in one-dimensional systems. We derive the first $O(\sqrt{T})$ frequentist regret bound for this problem, thus significantly improving the $O(T^{2/3})$ bound of Abeille & Lazaric (2017) and matching the frequentist performance derived by Abbasi-Yadkori & Szepesvári (2011) for an optimistic approach and the Bayesian result Ouyang et al. (2017) We obtain this result by developing a novel bound on the regret due to policy switches, which holds for LQ systems of any dimensionality and it allows updating the parameters and the policy at each step, thus overcoming previous limitations due to lazy updates. Finally, we report numerical simulations supporting the conjecture that our result extends to multi-dimensional systems.}
}

﻿@Article{Dean2019,
	author={Dean, Sarah
	and Mania, Horia
	and Matni, Nikolai
	and Recht, Benjamin
	and Tu, Stephen},
	title={On the Sample Complexity of the Linear Quadratic Regulator},
	journal={Foundations of Computational Mathematics},
	year={2019},
	month={Aug},
	day={05},
	abstract={This paper addresses the optimal control problem known as the linear quadratic regulator in the case when the dynamics are unknown. We propose a multistage procedure, called Coarse-ID control, that estimates a model from a few experimental trials, estimates the error in that model with respect to the truth, and then designs a controller using both the model and uncertainty estimate. Our technique uses contemporary tools from random matrix theory to bound the error in the estimation procedure. We also employ a recently developed approach to control synthesis called System Level Synthesis that enables robust control design by solving a quasi-convex optimization problem. We provide end-to-end bounds on the relative error in control cost that are optimal in the number of parameters and that highlight salient properties of the system to be controlled such as closed-loop sensitivity and optimal control magnitude. We show experimentally that the Coarse-ID approach enables efficient computation of a stabilizing controller in regimes where simple control schemes that do not take the model uncertainty into account fail to stabilize the true system.},
	issn={1615-3383},
	doi={10.1007/s10208-019-09426-y},
	url={https://doi.org/10.1007/s10208-019-09426-y}
}

@incollection{Dean2018,
	title = {Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator},
	author = {Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {4188--4197},
	year = {2018},
	publisher = {Curran Associates, Inc.},
}

@incollection{Schneider1997,
	title = {Exploiting Model Uncertainty Estimates for Safe Dynamic Control Learning},
	author = {Jeff G. Schneider},
	booktitle = {Advances in Neural Information Processing Systems 9},
	editor = {M. C. Mozer and M. I. Jordan and T. Petsche},
	pages = {1047--1053},
	year = {1997},
	publisher = {MIT Press},
	url = {http://papers.nips.cc/paper/1317-exploiting-model-uncertainty-estimates-for-safe-dynamic-control-learning.pdf}
}

@article{delos2015,
  TITLE = {{Minkowski Sum of Polytopes Defined by Their Vertices}},
  AUTHOR = {Delos, Vincent and Teissandier, Denis},
  JOURNAL = {{Journal of Applied Mathematics and Physics (JAMP)}},
  VOLUME = {3},
  NUMBER = {1},
  PAGES = {62-67},
  YEAR = {2015},
  MONTH = Jan,
}

@article{Mnih2015humanlevel,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	journal = {Nature},
	month = feb,
	number = {7540},
	pages = {529--533},
	publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	year = {2015}
}

@ARTICLE{Basar1996,
  author={T. {Basar} and P. {Bernhard}},
  journal={IEEE Transactions on Automatic Control},
  title={{H-infinity Optimal Control and Related Minimax Design Problems: A Dynamic Game Approach}},
  year={1996},
  volume={41},
  number={9},
  pages={1397-},
}

@inproceedings{Mansley2011,
	author = {Mansley, Chris and Weinstein, Ari and Littman, Michael},
	year = {2011},
	month = {01},
	title = {Sample-Based Planning for Continuous Action Markov Decision Processes.},
	journal = {Proceedings of the 21st International Conference on Automated Planning and Scheduling}
}

@inproceedings{Weinstein2012,
	author = {Weinstein, Ari and Littman, Michael L.},
	title = {Bandit-Based Planning and Learning in Continuous-Action Markov Decision Processes},
	year = {2012},
	publisher = {AAAI Press},
	booktitle = {Proceedings of the Twenty-Second International Conference on International Conference on Automated Planning and Scheduling (ICAPS 2012)},
	pages = {306--314},
	numpages = {9},
	month = jun,
	address = {Atibaia, S\~{a}o Paulo, Brazil},
	series = {ICAPS’12}
}

@ARTICLE{Efimov2012,
	author = {Efimov, D. and Fridman, L.M. and Ra\"issi, T. and Zolghadri, A. and
	Seydou, R.},
	title = {Interval Estimation for {LPV} Systems Applying High Order Sliding
	Mode Techniques},
	journal = {Automatica},
	year = {2012},
	volume = {48},
	pages = {2365--2371},
}

@article{Kumar2013,
	title = "Robust LQR Controller Design for Stabilizing and Trajectory Tracking of Inverted Pendulum",
	journal = "Procedia Engineering",
	volume = "64",
	pages = "169 - 178",
	year = "2013",
	note = "International Conference on Design and Manufacturing (IConDM2013)",
	issn = "1877-7058",
	doi = "https://doi.org/10.1016/j.proeng.2013.09.088",
	url = "http://www.sciencedirect.com/science/article/pii/S1877705813016020",
	author = "E. {Vinodh Kumar} and Jovitha Jerome",
	keywords = "Inverted Pendulum, LQR Controller, PV Controller, Riccatti Equation, Full State Feedback Controller, Pole placement approach",
	abstract = "This paper describes the method for stabilizing and trajectory tracking of Self Erecting Single Inverted Pendulum (SESIP) using Linear Quadratic Regulator (LQR). A robust LQR is proposed in this paper not only to stabilize the pendulum in upright position but also to make the cart system to track the given reference signal even in the presence of disturbance. The control scheme of pendulum system consists of two controllers such as swing up controller and stabilizing controller. The main focus of this work is on the design of stabilizing controller which can accommodate the disturbance present in the system in the form of wind force. An optimal LQR controller with well tuned weighting matrices is implemented to stabilize the pendulum in the vertical position. The steady state and dynamic characteristics of the proposed controller are investigated by conducting experiments on benchmark linear inverted pendulum system. Experimental results prove that the proposed LQR controller can guarantee the inverted pendulum a faster and smoother stabilizing process with less oscillation and better robustness than a Full State Feedback (FSF) controller by pole placement approach."
}

@inproceedings{Lenz2015,
  author    = {Ian Lenz and
               Ross A. Knepper and
               Ashutosh Saxena},
  editor    = {Lydia E. Kavraki and
               David Hsu and
               Jonas Buchli},
  title     = {DeepMPC: Learning Deep Latent Features for Model Predictive Control},
  booktitle = {Robotics: Science and Systems XI, 2015},
  month     = {July 13-17},
  address   = {Sapienza University of Rome, Rome, Italy},
  year      = {2015},
  url       = {http://www.roboticsproceedings.org/rss11/p12.html},
  doi       = {10.15607/RSS.2015.XI.012},
  timestamp = {Tue, 20 Nov 2018 15:31:10 +0100},
  biburl    = {https://dblp.org/rec/conf/rss/LenzKS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{Bental2009,
	title={Robust optimization},
	author={Ben-Tal, Aharon and El Ghaoui, Laurent and Nemirovski, Arkadi},
	volume={28},
	year={2009},
	publisher={Princeton University Press}
}
@article{Bertsimas2011,
	title={Theory and applications of robust optimization},
	author={Bertsimas, Dimitris and Brown, David B and Caramanis, Constantine},
	journal={SIAM review},
	volume={53},
	number={3},
	pages={464--501},
	year={2011},
	publisher={SIAM}
}

@article{Gorissen2015,
	title = "A practical guide to robust optimization",
	journal = "Omega",
	volume = "53",
	pages = "124 - 137",
	year = "2015",
	issn = "0305-0483",
	doi = "https://doi.org/10.1016/j.omega.2014.12.006",
	url = "http://www.sciencedirect.com/science/article/pii/S0305048314001698",
	author = "Bram L. Gorissen and İhsan Yanıkoğlu and Dick {den Hertog}",
	keywords = "Robust optimization, Adjustable robust optimization",
	abstract = "Robust optimization is a young and active research field that has been mainly developed in the last 15 years. Robust optimization is very useful for practice, since it is tailored to the information at hand, and it leads to computationally tractable formulations. It is therefore remarkable that real-life applications of robust optimization are still lagging behind; there is much more potential for real-life applications than has been exploited hitherto. The aim of this paper is to help practitioners to understand robust optimization and to successfully apply it in practice. We provide a brief introduction to robust optimization, and also describe important do׳s and don׳ts for using it in practice. We use many small examples to illustrate our discussions."
}

@phdthesis{le2012,
	TITLE = {Robust predictive control by zonotopic set-membership estimation.},
	AUTHOR = {Le, Vu Tuan Hieu},
	NUMBER = {2012SUPL0016},
	SCHOOL = {{Sup{\'e}lec}},
	YEAR = {2012},
	MONTH = Oct,
	KEYWORDS = {Uncertain system ; Model predictive control ; Set-membership estimation ; Syst{\`e}me incertain ; Estimation ensembliste ; Zonotope ; Commande pr{\'e}dictive},
	TYPE = {Theses}
}


@incollection{Ibrahimi2013,
	title = {Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems},
	author = {Morteza Ibrahimi and Javanmard, Adel and Benjamin V. Roy},
	booktitle = {Advances in Neural Information Processing Systems 25},
	editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
	pages = {2636--2644},
	year = {2012},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/4679-efficient-reinforcement-learning-for-high-dimensional-linear-quadratic-systems.pdf}
}

@article{Faradonbeh2020,
	author    = {Mohamad Kazem Shirani Faradonbeh and Ambuj Tewari and George Michailidis},
	title     = {Optimism-based adaptive regulation of linear-quadratic systems
	Systems},
	doi = {10.1109/TAC.2020.2998952},
	journal = {IEEE Transactions on Automatic Control},
	volume= {early access},
	year = {2020}
}

@INPROCEEDINGS{Ouyang2017,
  author={Yi Ouyang and Mukul Gagrani and Rahul Jain},
  booktitle={2017 55th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  title={Control of unknown linear systems with Thompson sampling},
  year={2017},
  month={3-6 Oct},
  address={Monticello, IL, USA},
  pages={1198-1205},
}


@inproceedings{Rosolia2019,
	abstract = {We present a sample-based Learning Model Predictive Controller (LMPC) for constrained uncertain linear systems subject to bounded additive disturbances. The proposed controller builds on earlier work on LMPC for deterministic systems. First, we introduce the design of the safe set and value function used to guarantee safety and performance improvement. Afterwards, we show how these quantities can be approximated using noisy historical data. The effectiveness of the proposed approach is demonstrated through a numerical example. We show that the LMPC is able to safely explore the state space and to iteratively improve the worst-case closed-loop performance, while robustly satisfying state and input constraints.},
	archivePrefix = {arXiv},
	arxivId = {1904.06432},
	author = {Rosolia, Ugo and Borrelli, Francesco},
    booktitle={2019 IEEE 58th Conference on Decision and Control (CDC)},
	doi = {10.1109/CDC40024.2019.9030270},
	eprint = {1904.06432},
	isbn = {9781728113982},
	issn = {07431546},
	title = {{Sample-Based Learning Model Predictive Control for Linear Uncertain Systems}},
	year = {2019},
	month = {11-13 Dec},
	address = {Nice, France},
    pages={2702-2707},
}

@InCollection{Sontag:01:Springer,
  author     = {Sontag, Eduardo D.},
  title      = {The {ISS} philosophy as a unifying framework for stability-like behavior},
  booktitle  = {Nonlinear control in the year 2000, {V}ol.\ 2 ({P}aris)},
  publisher  = {Springer},
  year       = {2001},
  volume     = {259},
  series     = {Lecture Notes in Control and Inform. Sci.},
  pages      = {443--467},
  address    = {London},
  mrclass    = {93D05 (93-02)},
  mrnumber   = {MR1806191 (2001k:93091)},
  mrreviewer = {Matthias Kawski},
  owner      = {EfDe},
  timestamp  = {2012.07.30},
}

@Article{Dashkovskiy:11:AiT,
  author    = {Dashkovskiy, S.N. and Efimov, D.V. and Sontag, E.D.},
  title     = {Input to state stability and allied system properties},
  journal   = {Automation and Remote Control},
  year      = {2011},
  volume    = {72},
  number    = {8},
  pages     = {1579--1614},
  owner     = {EfDe},
  timestamp = {2012.07.30},
}

@Article{Michalska1993,
  author  = {H. {Michalska} and D. Q. {Mayne}},
  title   = {Robust receding horizon control of constrained nonlinear systems},
  journal = {IEEE Transactions on Automatic Control},
  year    = {1993},
  volume  = {38},
  number  = {11},
  pages   = {1623--1633},
  doi     = {10.1109/9.262032},
}

@article{Mayne2000,
	title = "Constrained model predictive control: Stability and optimality",
	journal = "Automatica",
	volume = "36",
	number = "6",
	pages = "789 - 814",
	year = "2000",
	issn = "0005-1098",
	doi = "https://doi.org/10.1016/S0005-1098(99)00214-9",
	url = "http://www.sciencedirect.com/science/article/pii/S0005109899002149",
	author = "D.Q. Mayne and J.B. Rawlings and C.V. Rao and P.O.M. Scokaert",
	keywords = "Model predictive control, Stability, Optimality, Robustness",
	abstract = "Model predictive control is a form of control in which the current control action is obtained by solving, at each sampling instant, a finite horizon open-loop optimal control problem, using the current state of the plant as the initial state; the optimization yields an optimal control sequence and the first control in this sequence is applied to the plant. An important advantage of this type of control is its ability to cope with hard constraints on controls and states. It has, therefore, been widely applied in petro-chemical and related industries where satisfaction of constraints is particularly important because efficiency demands operating points on or close to the boundary of the set of admissible states and controls. In this review, we focus on model predictive control of constrained systems, both linear and nonlinear and discuss only briefly model predictive control of unconstrained nonlinear and/or time-varying systems. We concentrate our attention on research dealing with stability and optimality; in these areas the subject has developed, in our opinion, to a stage where it has achieved sufficient maturity to warrant the active interest of researchers in nonlinear control. We distill from an extensive literature essential principles that ensure stability and use these to present a concise characterization of most of the model predictive controllers that have been proposed in the literature. In some cases the finite horizon optimal control problem solved on-line is exactly equivalent to the same problem with an infinite horizon; in other cases it is equivalent to a modified infinite horizon optimal control problem. In both situations, known advantages of infinite horizon optimal control accrue."
}

@article{Mayne2009,
	title = "Robust output feedback model predictive control of constrained linear systems: Time varying case",
	journal = "Automatica",
	volume = "45",
	number = "9",
	pages = "2082 - 2087",
	year = "2009",
	issn = "0005-1098",
	doi = "https://doi.org/10.1016/j.automatica.2009.05.009",
	url = "http://www.sciencedirect.com/science/article/pii/S0005109809002544",
	author = "D.Q. Mayne and S.V. Raković and R. Findeisen and F. Allgöwer",
	keywords = "Output feedback, Robust model predictive control, State observer",
	abstract = "The problem of output feedback model predictive control of discrete time systems in the presence of additive but bounded state and output disturbances is considered. The overall controller consists of two components, a stable state estimator and a tube based, robustly stabilizing model predictive controller. Earlier results are extended by allowing the estimator to be time varying. The proposed robust output feedback controller requires the online solution of a standard quadratic program. The closed loop system renders a specified invariant set robustly exponentially stable."
}

@book{awan2014compensation,
  title={Compensation of Low Performance Steering System Using Torque Vectoring},
  author={Awan, M.A.},
  year={2014},
  publisher={Cranfield University}
}

@article{HomemDeMello2014,
title = "Monte Carlo sampling-based methods for stochastic optimization",
journal = "Surveys in Operations Research and Management Science",
volume = "19",
number = "1",
pages = "56 - 85",
year = "2014",
issn = "1876-7354",
doi = "https://doi.org/10.1016/j.sorms.2014.05.001",
author = "Tito Homem-de-Mello and Güzin Bayraksan",
abstract = "This paper surveys the use of Monte Carlo sampling-based methods for stochastic optimization problems. Such methods are required when—as it often happens in practice—the model involves quantities such as expectations and probabilities that cannot be evaluated exactly. While estimation procedures via sampling are well studied in statistics, the use of such methods in an optimization context creates new challenges such as ensuring convergence of optimal solutions and optimal values, testing optimality conditions, choosing appropriate sample sizes to balance the effort between optimization and estimation, and many other issues. Much work has been done in the literature to address these questions. The purpose of this paper is to give an overview of some of that work, with the goal of introducing the topic to students and researchers and providing a practical guide for someone who needs to solve a stochastic optimization problem with sampling."
}