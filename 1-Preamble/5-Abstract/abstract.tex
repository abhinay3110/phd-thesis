% ************************** Thesis Abstract *****************************
% Use `abstract' as an option in the document class to print only the titlepage and the abstract.
\begin{abstract}
% ----------------------------------------------------------------------------
\begin{center}
	\textbf{{\LARGE Résumé}}
\end{center}
% ----------------------------------------------------------------------------
\noindent
Dans cette thèse de doctorat, nous étudions comment des véhicules autonomes peuvent apprendre à garantir la \emph{sûreté} et à éviter les accidents, bien qu'ils partagent la route avec des conducteurs humains dont les comportements sont incertains. Pour prendre en compte cette incertitude, nous nous appuyons sur les observations en ligne de l'environnement pour construire une région de confiance autour de la dynamique du système, qui est ensuite propagée au cours du temps pour borner l'ensemble des trajectoires possibles des véhicules à proximité. Pour assurer la sûreté en présence de cette incertitude, nous avons recours à la prise de décision robuste, qui préconise de toujours considérer le pire cas. Cette approche garantit que la performance obtenue pendant la planification sera également atteinte sur le système réel, et nous montrons dans une analyse de bout en bout que la sous-optimalité qui en résulte est bornée. Nous en fournissons une implémentation efficace, basée sur des algorithmes de recherche arborescente. 

Une seconde contribution est motivée par le constat que cette approche pessimiste tend à produire des comportements excessivement prudents~: imaginez vouloir dépasser un véhicule, quelle certitude avez-vous que ce dernier ne changera pas de voie au tout dernier moment, provoquant un accident~? Ce type de raisonnement empêche les robots de conduire aisément parmi d'autres conducteurs, de s'insérer sur une autoroute ou de traverser une intersection, un phénomène connu sous le nom de \emph{«~robot figé~»}. Ainsi, la présence d'incertitude induit un compromis entre deux objectifs contradictoires~: sûreté et \emph{efficacité}. Comment arbitrer ce conflit~?
La question % elle est vite répondue
peut être temporairement contournée en réduisant au maximum l'incertitude. Par exemple, nous proposons une architecture de réseau de neurones basée sur de l'attention, qui tient compte des interactions entre véhicules pour améliorer ses prédictions. Mais pour aborder pleinement ce compromis, nous nous appuyons sur la prise de décision sous contrainte afin de considérer indépendamment les deux objectifs de sûreté et d'efficacité. Au lieu d'une unique politique de conduite, nous entrainons toute une gamme de comportements, variant du plus prudent au plus agressif.  Ainsi, le concepteur du système dispose d'un curseur lui permettant d'ajuster en temps réel le niveau de risque assumé par le véhicule.

% ----------------------------------------------------------------------------
%\hr{}
\newpage

% \newpage
% ----------------------------------------------------------------------------
\begin{center}
	\textbf{{\LARGE Abstract}}
\end{center}
In this Ph.D. thesis, we study how autonomous vehicles can learn to act \emph{safely} and avoid accidents, despite sharing the road with human drivers whose behaviours are uncertain. To explicitly account for this uncertainty, informed by online observations of the environment, we construct a high-confidence region over the system dynamics, which we propagate through time to bound the possible trajectories of nearby traffic. To ensure safety under such uncertainty, we resort to robust decision-making and act by always considering the worst-case outcomes. This approach guarantees that the performance reached during planning is at least achieved for the true system, and we show by end-to-end analysis that the overall sub-optimality is bounded. Tractability is preserved at all stages, by leveraging sample-efficient tree-based planning algorithms.

Another contribution is motivated by the observation that this pessimistic approach tends to produce overly conservative behaviours: imagine you wish to overtake a vehicle, what certainty do you have that they will not change lane at the very last moment, causing an accident? Such reasoning makes it difficult for robots to drive amidst other drivers, merge into a highway, or cross an intersection --an issue colloquially known as the \emph{\enquote{freezing robot problem}}.
Thus, the presence of uncertainty induces a trade-off between two contradictory objectives: safety and \emph{efficiency}. How does one arbitrate this conflict?
The question can be temporarily circumvented by reducing uncertainty as much as possible. For instance, we propose an attention-based neural network architecture that better accounts for interactions between traffic participants to improve predictions. But to actively embrace this trade-off, we draw on constrained decision-making to consider both the task completion and safety objectives independently. Rather than a unique driving policy, we train a whole continuum of behaviours, ranging from conservative to aggressive. This provides the system designer with a slider allowing them to adjust the level of risk assumed by the vehicle in real-time.
\end{abstract}
