@Comment{Chap1,
	title =	 {Introduction},
}

@article{Foot1967,
	volume = {5},
	pages = {5--15},
	title = {The Problem of Abortion and the Doctrine of Double Effect},
	year = {1967},
	journal = {Oxford Review},
	author = {Philippa Foot}
}

@Inbook{Lin2015,
	author={Lin, Patrick},
	title={Why Ethics Matters for Autonomous Cars},
	bookTitle={Autonomes Fahren: Technische, rechtliche und gesellschaftliche Aspekte},
	year={2015},
	publisher={Springer Berlin Heidelberg},
	address={Berlin, Heidelberg},
	pages={69--85},
	abstract={If motor vehicles are to be truly autonomous and able to operate responsibly on our roads, they will need to replicate -- or do better than -- the human decision-making process. But some decisions are more than just a mechanical application of traffic laws and plotting a safe path. They seem to require a sense of ethics, and this is a notoriously difficult capability to reduce into algorithms for a computer to follow.},
	isbn={978-3-662-45854-9},
	doi={10.1007/978-3-662-45854-9_4},
	url={https://doi.org/10.1007/978-3-662-45854-9_4}
	}

@article{Bonnefon2016,
	title={The social dilemma of autonomous vehicles},
	volume={352},
	ISSN={1095-9203},
	url={http://dx.doi.org/10.1126/science.aaf2654},
	DOI={10.1126/science.aaf2654},
	number={6293},
	journal={Science},
	publisher={American Association for the Advancement of Science (AAAS)},
	author={Bonnefon, J.-F. and Shariff, A. and Rahwan, I.},
	year={2016},
	month={Jun},
	pages={1573–1576}
}

@article{Gogoll2017,
	abstract = {The recent progress in the development of autonomous cars has seen ethical questions come to the forefront. In particular, life and death decisions regarding the behavior of self-driving cars in trolley dilemma situations are attracting widespread interest in the recent debate. In this essay we want to ask whether we should implement a mandatory ethics setting (MES) for the whole of society or, whether every driver should have the choice to select his own personal ethics setting (PES). While the consensus view seems to be that people would not be willing to use an automated car that might sacrifice themselves in a dilemma situation, we will defend the somewhat contra-intuitive claim that this would be nevertheless in their best interest. The reason is, simply put, that a PES regime would most likely result in a prisoner's dilemma.},
	author = {Gogoll, Jan and M{\"{u}}ller, Julian F.},
	doi = {10.1007/s11948-016-9806-x},
	issn = {14715546},
	journal = {Science and Engineering Ethics},
	keywords = {Automation,Autonomous driving,Dilemma,Ethics,Morality},
	title = {{Autonomous Cars: In Favor of a Mandatory Ethics Setting}},
	year = {2017}
}

@article{Awad2018,
	author={Awad, Edmond
	and Dsouza, Sohan
	and Kim, Richard
	and Schulz, Jonathan
	and Henrich, Joseph
	and Shariff, Azim
	and Bonnefon, Jean-Fran{\c{c}}ois
	and Rahwan, Iyad},
	title={The Moral Machine experiment},
	journal={Nature},
	year={2018},
	month={Nov},
	day={01},
	volume={563},
	number={7729},
	pages={59-64},
	abstract={With the rapid development of artificial intelligence have come concerns about how machines will make moral decisions, and the major challenge of quantifying societal expectations about the ethical principles that should guide machine behaviour. To address this challenge, we deployed the Moral Machine, an online experimental platform designed to explore the moral dilemmas faced by autonomous vehicles. This platform gathered 40 million decisions in ten languages from millions of people in 233 countries and territories. Here we describe the results of this experiment. First, we summarize global moral preferences. Second, we document individual variations in preferences, based on respondents' demographics. Third, we report cross-cultural ethical variation, and uncover three major clusters of countries. Fourth, we show that these differences correlate with modern institutions and deep cultural traits. We discuss how these preferences can contribute to developing global, socially acceptable principles for machine ethics. All data used in this article are publicly available.},
	issn={1476-4687},
	doi={10.1038/s41586-018-0637-6},
	url={https://doi.org/10.1038/s41586-018-0637-6}
}

@inproceedings{Noothigattu2018,
	title={A voting-based system for ethical decision making},
	author={Noothigattu, Ritesh and Gaikwad, Snehalkumar S and Awad, Edmond and Dsouza, Sohan and Rahwan, Iyad and Ravikumar, Pradeep and Procaccia, Ariel D},
	booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
	year={2018}
}

@misc{DeFreitas2019,
	title={Doubting Driverless Dilemmas},
	url={psyarxiv.com/a36e5},
	DOI={10.31234/osf.io/a36e5},
	publisher={PsyArXiv},
	author={De Freitas, Julian and Anthony, Sam E and Alvarez, George and Censi, Andrea},
	year={2019},
	month={Jan}
}

@misc{trolley2009,
	author = {Jesse Prinz},
	title = {Subcortex.com},
	year = 2009,
	howpublished={\url{http://subcortex.com/}},
	urldate = {2010-09-30}
}

@book{Buehler2009,
	author = {Buehler, Martin and Iagnemma, Karl and Singh, Sanjiv},
	title = {The DARPA Urban Challenge: Autonomous Vehicles in City Traffic},
	year = {2009},
	isbn = {3642039901},
	publisher = {Springer Publishing Company, Incorporated},
	edition = {1st}
}

@phdthesis{Polack2018,
	title = {{Consistency and stability of hierarchical planning and control systems for autonomous driving}},
	author = {Polack, Philip},
	url = {https://pastel.archives-ouvertes.fr/tel-02096788},
	number = {2018PSLEM025},
	school = {{PSL Research University}},
	year = {2018},
	month = Oct,
	keywords = {Vehicle dynamics ; Motion planning ; Autonomous driving ; Model predictive control ; Model-free control ; Longitudinal and lateral control ; Planification de trajectoire ; Conduite autonome ; Commande pr{\'e}dictive {\`a} mod{\`e}le ; Contr{\^o}le longitudinal et lat{\'e}ral ; Dynamique du v{\'e}hicule},
	type = {Theses},
	pdf = {https://pastel.archives-ouvertes.fr/tel-02096788/file/2018PSLEM025_archivage.pdf},
	hal_id = {tel-02096788},
	hal_version = {v1},
}

@Comment{Chap2_1,
	title =	 {Motion Planning},
}

@article{Gonzalez2016,
	author={D. {González} and J. {Pérez} and V. {Milanés} and F. {Nashashibi}},
	journal={IEEE Transactions on Intelligent Transportation Systems}, 
	title={A Review of Motion Planning Techniques for Automated Vehicles}, 
	year={2016},
	volume={17},
	number={4},
	pages={1135-1145},
}

@article{Paden2016,
	author    = {Brian Paden and
	Michal C{\'{a}}p and
	Sze Zheng Yong and
	Dmitry S. Yershov and
	Emilio Frazzoli},
	title     = {A Survey of Motion Planning and Control Techniques for Self-driving
	Urban Vehicles},
	journal   = {CoRR},
	volume    = {abs/1604.07446},
	year      = {2016},
	url       = {http://arxiv.org/abs/1604.07446},
	archivePrefix = {arXiv},
	eprint    = {1604.07446},
	timestamp = {Mon, 13 Aug 2018 16:49:15 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/PadenCYYF16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Dijkstra1959,
	author = {Dijkstra, E. W.},
	doi = {10.1007/BF01386390},
	issn = {0029599X},
	journal = {Numerische Mathematik},
	title = {{A note on two problems in connexion with graphs}},
	year = {1959}
}

@article{Hart1968,
	abstract = {Although the problem of determining the minimum cost path through a graph arises naturally in a number of interesting applications, there has been no underlying theory to guide the development of efficient search procedures. Moreover, there is no adequate conceptual framework within which the various ad hoc search strategies proposed to date can be compared. This paper describes how heuristic information from the problem domain can be incorporated into a formal mathematical theory of graph searching and demonstrates an optimality property of a class of search strategies. Copyright {\textcopyright} 1968 by The Institute of Electrical and Electronics Engineers, Inc.},
	author = {Hart, Peter E. and Nilsson, Nils J. and Raphael, Bertram},
	doi = {10.1109/TSSC.1968.300136},
	issn = {21682887},
	journal = {IEEE Transactions on Systems Science and Cybernetics},
	title = {{A Formal Basis for the Heuristic Determination of Minimum Cost Paths}},
	year = {1968}
}

@inproceedings{Stentz1994,
	abstract = {The task of planning trajectories for a mobile robot has received considerable attention in the research literature. Most of the work assumes the robot has a complete and accurate model of its environment before it begins to move; less attention has been paid to the problem of partially known environments. This situation occurs for an exploratory robot or one that must move to a goal location without the benefit of a floorplan or terrain map. Existing approaches plan an initial path based on known information and then modify the plan locally or replan the entire path as the robot discovers obstacles with its sensors, sacrificing optimality or computational efficiency respectively. This paper introduces a new algorithm, D, capable of planning paths in unknown, partially known, and changing environments in an efficient, optimal, and complete manner.},
	author = {Stentz, Anthony},
	booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
	doi = {10.1109/robot.1994.351061},
	isbn = {0818653329},
	issn = {10504729},
	title = {{Optimal and efficient path planning for partially-known environments}},
	year = {1994}
}

@inproceedings{Ziegler2009,
	abstract = {We present a method for motion planning in the presence of moving obstacles that is aimed at dynamic on-road driving scenarios. Planning is performed within a geometric graph that is established by sampling deterministically from a manifold that is obtained by combining configuration space and time. We show that these graphs are acyclic and shortest path algorithms with linear runtime can be employed. By reparametrising the configuration space to match the course of the road, it can be sampled very economically with few vertices, and this reduces absolute runtime further. The trajectories generated are quintic splines. They are second order continuous, obey nonholonomic constraints and are optimised for minimum square of jerk. Planning time remains below 20 ms on general purpose hardware. {\textcopyright} 2009 IEEE.},
	author = {Ziegler, Julius and Stiller, Christoph},
	booktitle = {2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2009},
	doi = {10.1109/IROS.2009.5354448},
	isbn = {9781424438044},
	title = {{Spatiotemporal state lattices for fast trajectory planning in dynamic on-road driving scenarios}},
	year = {2009}
}

@article{Bohren2008,
	abstract = {This paper describes "Little Ben," an autonomous ground vehicle constructed by the Ben Franklin Racing Team for the 2007 DARPA Urban Challenge in under a year and for less than {\$}250,000. The sensing, planning, navigation, and actuation systems for Little Ben were carefully designed to meet the performance demands required of an autonomous vehicle traveling in an uncertain urban environment. We incorporated an array of a global positioning system (GPS)/inertial navigation system, LIDARs, and stereo cameras to provide timely information about the surrounding environment at the appropriate ranges. This sensor information was integrated into a dynamic map that could robustly handle GPS dropouts and errors. Our planning algorithms consisted of a high-level mission planner that used information from the provided route network definition and mission data files to select routes, whereas the lower level planner used the latest dynamic map information to optimize a feasible trajectory to the next waypoint. The vehicle was actuated by a cost-based controller that efficiently handled steering, throttle, and braking maneuvers in both forward and reverse directions. Our software modules were integrated within a hierarchical architecture that allowed rapid development and testing of the system performance. The resulting vehicle was one of six to successfully finish the Urban Challenge. {\textcopyright} 2008 Wiley Periodicals, Inc.},
	author = {Bohren, Jonathan and Foote, Tully and Keller, Jim and Kushleyev, Alex and Lee, Daniel and Stewart, Alex and Vernaza, Paul and Derenick, Jason and Spletzer, John and Satterfield, Brian},
	doi = {10.1002/rob.20260},
	issn = {15564959},
	journal = {Journal of Field Robotics},
	title = {{Little Ben: The Ben Franklin Racing Team's entry in the 2007 DARPA Urban Challenge}},
	year = {2008}
}

@article{Bacha2008,
	abstract = {The DARPA Urban Challenge required robotic vehicles to travel more than 90 km through an urban environment without human intervention and included situations such as stop intersections, traffic merges, parking, and roadblocks. Team VictorTango separated the problem into three parts: base vehicle, perception, and planning. A Ford Escape outfitted with a custom drive-by-wire system and computers formed the basis for Odin. Perception used laser scanners, global positioning system, and a priori knowledge to identify obstacles, cars, and roads. Planning relied on a hybrid deliberative/reactive architecture toanalyze the situation, select the appropriate behavior, and plan a safe path. All vehicle modules communicated using the JAUS (Joint Architecture for Unmanned Systems) standard. The performance of these components in the Urban Challenge is discussed and successes noted. The result of VictorTango's work was successful completion of the Urban Challenge and a third-place finish. {\textcopyright} 2008 Wiley Periodicals, Inc.},
	author = {Bacha, Andrew and Bauman, Cheryl and Faruque, Ruel and Fleming, Michael and Terwelp, Chris and Reinholtz, Charles and Hong, Dennis and Wicks, Al and Alberi, Thomas and Anderson, David and Cacciola, Stephen and Currier, Patrick and Dalton, Aaron and Farmer, Jesse and Hurdus, Jesse and Kimmel, Shawn and King, Peter and Taylor, Andrew and van Covern, David and Webster, Mike},
	doi = {10.1002/rob.20248},
	issn = {15564959},
	journal = {Journal of Field Robotics},
	title = {{Odin: Team VictorTango's entry in the DARPA Urban Challenge}},
	year = {2008}
}

@article{Montemerlo2008,
	abstract = {This article presents the architecture of Junior, a robotic vehicle capable of navigating urban environments autonomously. In doing so, the vehicle is able to select its own routes, perceive and interact with other traffic, and execute various urban driving skills including lane changes, U-turns, parking, and merging into moving traffic. The vehicle successfully finished and won second place in the DARPA Urban Challenge, a robot competition organized by the U.S. Government. {\textcopyright} 2008 Wiley Periodicals, Inc.},
	author = {Montemerlo, Michael and Becker, Jan and Shat, Suhrid and Dahlkamp, Hendrik and Dolgov, Dmitri and Ettinger, Scott and Haehnel, Dirk and Hilden, Tim and Hoffmann, Gabe and Huhnke, Burkhard and Johnston, Doug and Klumpp, Stefan and Langer, Dirk and Levandowski, Anthony and Levinson, Jesse and Marcil, Julien and Orenstein, David and Paefgen, Johannes and Penny, Isaac and Petrovskaya, Anna and Pflueger, Mike and Stanek, Ganymed and Stavens, David and Vogt, Antone and Thrun, Sebastian},
	doi = {10.1002/rob.20258},
	issn = {15564959},
	journal = {Journal of Field Robotics},
	title = {{Junior: The Stanford entry in the urban challenge}},
	year = {2008}
}

@article{Kammel2008,
	abstract = {This paper reports on AnnieWAY, an autonomous vehicle that is capable of driving through urban scenarios and that successfully entered the finals of the 2007 DARPA Urban Challenge competition. After describing the main challenges imposed and the major hardware components, we outline the underlying software structure and focus on selected algorithms. Environmental perception mainly relies on a recent laser scanner that delivers both range and reflectivity measurements. Whereas range measurements are used to provide three-dimensional scene geometry, measuring reflectivity allows for robust lane marker detection. Mission and maneuver planning is conducted using a hierarchical state machine that generates behavior in accordance with California traffic laws. We conclude with a report of the results achieved during the competition. {\textcopyright} 2008 Wiley Periodicals, Inc.},
	author = {Kammel, S{\"{o}}ren and Ziegler, Julius and Pitzer, Benjamin and Werling, Moritz and Gindele, Tobias and Jagzent, Daniel and Schr{\"{o}}der, Joachim and Thuy, Michael and Goebl, Matthias and von Hundelshausen, Felix and Pink, Oliver and Frese, Christian and Stiller, Christoph},
	doi = {10.1002/rob.20252},
	issn = {15564959},
	journal = {Journal of Field Robotics},
	title = {{Team AnnieWAY's autonomous system for the 2007 DARPA Urban Challenge}},
	year = {2008}
}

@article{Urmson2008,
	abstract = {Boss is an autonomous vehicle that uses on-board sensors (global positioning system, lasers, radars, and cameras) to track other vehicles, detect static obstacles, and localize itself relative to a road model. A three-layer planning system combines mission, behavioral, and motion planning to drive in urban environments. The mission planning layer considers which street to take to achieve a mission goal. The behavioral layer determines when to change lanes and precedence at intersections and performs error recovery maneuvers. The motion planning layer selects actions to avoid obstacles while making progress toward local goals. The system was developed from the ground up to address the requirements of the DARPA Urban Challenge using a spiral system development process with a heavy emphasis on regular, regressive system testing. During the National Qualification Event and the 85-km Urban Challenge Final Event, Boss demonstrated some of its capabilities, qualifying first and winning the challenge. {\textcopyright} 2008 Wiley Periodicals, Inc.},
	author = {Urmson, Chris and Anhalt, Joshua and Bagnell, Drew and Baker, Christopher and Bittner, Robert and Clark, M. N. and Dolan, John and Duggins, Dave and Galatali, Tugrul and Geyer, Chris and Gittleman, Michele and Harbaugh, Sam and Hebert, Martial and Howard, Thomas M. and Kolski, Sascha and Kelly, Alonzo and Likhachev, Maxim and McNaughton, Matt and Miller, Nick and Peterson, Kevin and Pilnick, Brian and Rajkumar, Raj and Rybski, Paul and Salesky, Bryan and Seo, Young Woo and Singh, Sanjiv and Snider, Jarrod and Stentz, Anthony and Whittaker, William and Wolkowicki, Ziv and Ziglar, Jason and Bae, Hong and Brown, Thomas and Demitrish, Daniel and Litkouhi, Bakhtiar and Nickolaou, Jim and Sadekar, Varsha and Zhang, Wende and Struble, Joshua and Taylor, Michael and Darms, Michael and Ferguson, Dave},
	doi = {10.1002/rob.20255},
	issn = {15564959},
	journal = {Journal of Field Robotics},
	title = {{Autonomous driving in urban environments: Boss and the urban challenge}},
	year = {2008}
}

@techreport{Lavalle98,
	author = {Steven M. Lavalle},
	title = {Rapidly-Exploring Random Trees: A New Tool for Path Planning},
	institution = {Computer Science Department, Iowa State University},
	year = {1998}
}

@inproceedings{Karaman2011,
	abstract = {During the last decade, sampling-based path planning algorithms, such as probabilistic roadmaps (PRM) and rapidly exploring random trees (RRT), have been shown to work well in practice and possess theoretical guarantees such as probabilistic completeness. However, little effort has been devoted to the formal analysis of the quality of the solution returned by such algorithms, e.g. as a function of the number of samples. The purpose of this paper is to fill this gap, by rigorously analyzing the asymptotic behavior of the cost of the solution returned by stochastic sampling-based algorithms as the number of samples increases. A number of negative results are provided, characterizing existing algorithms, e.g. showing that, under mild technical conditions, the cost of the solution returned by broadly used sampling-based algorithms converges almost surely to a non-optimal value. The main contribution of the paper is the introduction of new algorithms, namely, PRM* and RRT*, which are provably asymptotically optimal, i.e. such that the cost of the returned solution converges almost surely to the optimum. Moreover, it is shown that the computational complexity of the new algorithms is within a constant factor of that of their probabilistically complete (but not asymptotically optimal) counterparts. The analysis in this paper hinges on novel connections between stochastic sampling-based path planning algorithms and the theory of random geometric graphs. {\textcopyright} The Author(s) 2011.},
	author = {Karaman, Sertac and Frazzoli, Emilio},
	booktitle = {International Journal of Robotics Research},
	doi = {10.1177/0278364911406761},
	issn = {02783649},
	keywords = {Motion planning,Optimal path planning,Random geometric graphs,Sampling-based algorithms},
	title = {{Sampling-based algorithms for optimal motion planning}},
	year = {2011}
}

@article{Kavraki1996,
	abstract = {A new motion planning method for robots in static workspaces is presented. This method proceeds in two phases: a learning phase and a query phase. In the learning phase, a probabilistic roadmap is constructed and stored as a graph whose nodes correspond to collision-free configurations and whose edges correspond to feasible paths between these configurations. These paths are computed using a simple and fast local planner. In the query phase, any given start and goal configurations of the robot are connected to two nodes of the roadmap; the roadmap is then searched for a path joining these two nodes. The method is general and easy to implement. It can be applied to virtually any type of holonomic robot. It requires selecting certain parameters (e.g., the duration of the learning phase) whose values depend on the scene, that is the robot and its workspace. But these values turn out to be relatively easy to choose. Increased efficiency can also be achieved by tailoring some components of the method (e.g., the local planner) to the considered robots. In this paper the method is applied to planar articulated robots with many degrees of freedom. Experimental results show that path planning can be done in a fraction of a second on a contemporary workstation (≈ 150 MIPS), after learning for relatively short periods of time (a few dozen seconds). {\textcopyright} 1996 IEEE.},
	author = {Kavraki, Lydia E. and {\v{S}}vestka, Petr and Latombe, Jean Claude and Overmars, Mark H.},
	doi = {10.1109/70.508439},
	issn = {1042296X},
	journal = {IEEE Transactions on Robotics and Automation},
	title = {{Probabilistic roadmaps for path planning in high-dimensional configuration spaces}},
	year = {1996}
}

@inproceedings{Kocsis2006,
	abstract = {For large state-space Markovian Decision Problems Monte-Carlo planning is one of the few viable approaches to find near-optimal solutions. In this paper we introduce a new algorithm, UCT, that applies bandit ideas to guide Monte-Carlo planning. In finite-horizon or discounted MDPs the algorithm is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling. Experimental results show that in several domains, UCT is significantly more efficient than its alternatives. {\textcopyright} Springer-Verlag Berlin Heidelberg 2006.},
	author = {Kocsis, Levente and Szepesv{\'{a}}ri, Csaba},
	booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	doi = {10.1007/11871842_29},
	isbn = {354045375X},
	issn = {16113349},
	title = {{Bandit based Monte-Carlo planning}},
	year = {2006}
}

@article{Reeds1990,
	abstract = {The path taken by a car with a given minimum turning radius has a lower bound on its radius of curvature at each point, but the path has cusps if the car shifts into or out of reverse gear. What is the shortest such path a car can travel between two points if its starting and ending directions are specified? One need consider only paths with at most 2 cusps or reversals. We give a set of paths which is sufficient in the sense that it always contains a shortest path and small in the sense that there are at most 68, but usually many fewer paths in the set for any pair of endpoints and directions. We give these paths by explicit formula. Calculating the length of each of these paths and selecting the (not necessarily unique) path with smallest length yields a simple algorithm for a shortest path in each case. These optimal paths or geodesies may be described as follows: If C is an arc of a circle of the minimal turning radius and S is a line segment, then it is sufficient to consider only certain paths of the form CCSCC where arcs and segments fit smoothly, one or more of the arcs or segments may vanish, and where reversals, or equivalently cusps, between arcs or segments are allowed. This contrasts with the case when cusps are not allowed, where Dubins (1957) has shown that paths of the form CCC and CSC suffice. {\textcopyright} 1990 by Pacific Journal of Mathematics.},
	author = {Reeds, J. A. and Shepp, L. A.},
	doi = {10.2140/pjm.1990.145.367},
	issn = {00308730},
	journal = {Pacific Journal of Mathematics},
	title = {{Optimal paths for a car that goes both forwards and backwards}},
	year = {1990}
}

@inproceedings{Xu2012,
	abstract = {In this paper, an efficient real-time autonomous driving motion planner with trajectory optimization is proposed. The planner first discretizes the plan space and searches for the best trajectory based on a set of cost functions. Then an iterative optimization is applied to both the path and speed of the resultant trajectory. The post-optimization is of low computational complexity and is able to converge to a higher-quality solution within a few iterations. Compared with the planner without optimization, this framework can reduce the planning time by 52{\%} and improve the trajectory quality. The proposed motion planner is implemented and tested both in simulation and on a real autonomous vehicle in three different scenarios. Experiments show that the planner outputs high-quality trajectories and performs intelligent driving behaviors. {\textcopyright} 2012 IEEE.},
	author = {Xu, Wenda and Wei, Junqing and Dolan, John M. and Zhao, Huijing and Zha, Hongbin},
	booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
	doi = {10.1109/ICRA.2012.6225063},
	isbn = {9781467314039},
	issn = {10504729},
	title = {{A real-time motion planner with trajectory optimization for autonomous vehicles}},
	year = {2012}
}

@inproceedings{Gonzalez2014,
	abstract = {This paper presents a continuous curvature planning algorithm with obstacle avoidance capabilities. The automated system generates a collision free path that considers vehicle's constraints, the road and different obstacles inside the horizon of view. The developed planning module was integrated in the RITS (former IMARA) autonomous vehicle architecture. The goal of this module is to obtain an accurate, continuous and safe path generation, by implementing parametric curves. To this end, a continuous curvature profile when calculating vehicle trajectory is introduced. It also permits to generate different speed profiles, improving the comfort by reducing lateral accelerations in the driving process. These algorithms have been implemented in simulated -ProSiVIC- and real platforms -Cybercars- showing good results in both cases. This approach is currently being implemented in the framework of the EU CityMobil2 project.},
	author = {Gonz{\'{a}}lez, David and P{\'{e}}rez, Joshue and Lattarulo, Ray and Milan{\'{e}}s, Vicente and Nashashibi, Fawzi},
	booktitle = {2014 17th IEEE International Conference on Intelligent Transportation Systems, ITSC 2014},
	doi = {10.1109/ITSC.2014.6957887},
	isbn = {9781479960781},
	title = {{Continuous curvature planning with obstacle avoidance capabilities in urban scenarios}},
	year = {2014}
}

@inproceedings{Funke2012,
	abstract = {This paper presents a novel approach to autonomous driving at the vehicle's handling limits. Such a system requires a high speed, consistent control signal as well as numerous safety features capable of monitoring and stopping the vehicle. When operating, the system's high level controller utilizes a highly accurate differential GPS and known friction values to drive a precomputed path at the friction limits of the vehicle. The system was tested in a variety of road conditions, including the challenging Pikes Peak Hill climb. Results from this work can be extended to improve driving safety and accident avoidance in vehicles. {\textcopyright} 2012 IEEE.},
	author = {Funke, Joseph and Theodosis, Paul and Hindiyeh, Rami and Stanek, Ganymed and Kritatakirana, Krisada and Gerdes, Chris and Langer, Dirk and Hernandez, Marcial and M{\"{u}}ller-Bessler, Bernhard and Huhnke, Burkhard},
	booktitle = {IEEE Intelligent Vehicles Symposium, Proceedings},
	doi = {10.1109/IVS.2012.6232212},
	isbn = {9781467321198},
	title = {{Up to the limits: Autonomous Audi TTS}},
	year = {2012}
}

@article{Pivtoraiko2005,
	abstract = {We propose a novel approach to constrained path planning that is based on a special search space which efficiently encodes feasible paths. The paths are encoded implicitly as connections between states, but only feasible and local connections are included. Once this search space is developed, we systematically generate a near-minimal set of spatially distinct path primitives. This set expresses the local connectivity of constrained motions and also eliminates redundancies. The set of primitives is used to define heuristic search, and thereby create a very efficient path planner at the chosen resolution. We also discuss a wide variety of space and terrestrial robotics applications where this motion planner can be especially useful.},
	author = {Pivtoraiko, Mihail and Kelly, Alonzo},
	issn = {03796566},
	journal = {European Space Agency, (Special Publication) ESA SP},
	keywords = {Control set,Differential constraints,Lattice,Nonholonomic,Path planning,Path/motion primitives},
	title = {{Efficient constrained path planning via search in state lattices}},
	year = {2005}
}

@Comment{Chap2_2,
	title =	 {Imitation Learning},
}

@incollection{Pomerleau89,
	title = {ALVINN: An Autonomous Land Vehicle in a Neural Network},
	author = {Pomerleau, Dean A.},
	booktitle = {Advances in Neural Information Processing Systems 1},
	editor = {D. S. Touretzky},
	pages = {305--313},
	year = {1989},
	publisher = {Morgan-Kaufmann},
	url = {http://papers.nips.cc/paper/95-alvinn-an-autonomous-land-vehicle-in-a-neural-network.pdf}
}

@misc{Levine2016,
	abstract = {Policy search methods can allow robots to learn control policies for a wide range of tasks, but practical applications of policy search often require hand-engineered components for perception, state estimation, and low-level control. In this paper, we aim to answer the following question: does training the perception and control systems jointly end-to-end provide better performance than training each component separately? To this end, we develop a method that can be used to learn policies that map raw image observations directly to torques at the robot's motors. The policies are represented by deep convolutional neural networks (CNNs) with 92,000 parameters, and are trained using a guided policy search method, which transforms policy search into supervised learning, with supervision provided by a simple trajectory-centric reinforcement learning method. We evaluate our method on a range of real-world manipulation tasks that require close coordination between vision and control, such as screwing a cap onto a bottle, and present simulated comparisons to a range of prior policy search methods.},
	author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
	booktitle = {Journal of Machine Learning Research},
	issn = {15337928},
	keywords = {Neural networks,Optimal control,Reinforcement learning,Vision},
	title = {{End-to-end training of deep visuomotor policies}},
	year = {2016}
}

@inproceedings{Ross2011,
	abstract = {Sequential prediction problems such as imitation learning, where future observations depend on previous predictions (actions), violate the common i.i.d. assumptions made in statistical learning. This leads to poor performance in theory and often in practice. Some recent approaches (Daum{\'{e}} III et al., 2009; Ross and Bagnell, 2010) provide stronger guarantees in this setting, but remain somewhat unsatisfactory as they train either non-stationary or stochastic policies and require a large number of iterations. In this paper, we propose a new iterative algorithm, which trains a stationary deterministic policy, that can be seen as a no regret algorithm in an online learning setting. We show that any such no regret algorithm, combined with additional reduction assumptions, must find a policy with good performance under the distribution of observations it induces in such sequential settings. We demonstrate that this new approach outperforms previous approaches on two challenging imitation learning problems and a benchmark sequence labeling problem. Copyright 2011 by the authors.},
	author = {Ross, St{\'{e}}phane and Gordon, Geoffrey J. and Bagnell, J. Andrew},
	booktitle = {Journal of Machine Learning Research},
	issn = {15324435},
	title = {{A reduction of imitation learning and structured prediction to no-regret online learning}},
	year = {2011}
}

@article{Bojarski2016,
	author    = {Mariusz Bojarski and
	Davide Del Testa and
	Daniel Dworakowski and
	Bernhard Firner and
	Beat Flepp and
	Prasoon Goyal and
	Lawrence D. Jackel and
	Mathew Monfort and
	Urs Muller and
	Jiakai Zhang and
	Xin Zhang and
	Jake Zhao and
	Karol Zieba},
	title     = {End to End Learning for Self-Driving Cars},
	journal   = {CoRR},
	volume    = {abs/1604.07316},
	year      = {2016},
	url       = {http://arxiv.org/abs/1604.07316},
	archivePrefix = {arXiv},
	eprint    = {1604.07316},
	timestamp = {Mon, 13 Aug 2018 16:47:06 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/BojarskiTDFFGJM16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Xu2017,
	abstract = {Robust perception-action models should be learned from training data with diverse visual appearances and realistic behaviors, yet current approaches to deep visuomotor policy learning have been generally limited to in-situ models learned from a single vehicle or simulation environment. We advocate learning a generic vehicle motion model from large scale crowd-sourced video data, and develop an endto-end trainable architecture for learning to predict a distribution over future vehicle egomotion from instantaneous monocular camera observations and previous vehicle state. Our model incorporates a novel FCN-LSTM architecture, which can be learned from large-scale crowd-sourced vehicle action data, and leverages available scene segmentation side tasks to improve performance under a privileged learning paradigm. We provide a novel large-scale dataset of crowd-sourced driving behavior suitable for training our model, and report results predicting the driver action on held out sequences across diverse conditions.},
	archivePrefix = {arXiv},
	arxivId = {1612.01079},
	author = {Xu, Huazhe and Gao, Yang and Yu, Fisher and Darrell, Trevor},
	booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
	doi = {10.1109/CVPR.2017.376},
	eprint = {1612.01079},
	isbn = {9781538604571},
	title = {{End-to-end learning of driving models from large-scale video datasets}},
	year = {2017}
}

@misc{Eraqi2017,
	title={End-to-End Deep Learning for Steering Autonomous Vehicles Considering Temporal Dependencies},
	author={Hesham M. Eraqi and Mohamed N. Moustafa and Jens Honer},
	year={2017},
	eprint={1710.03804},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@inproceedings{Ho2016,
	abstract = {Consider learning a policy from example expert behavior, without interaction with the expert or access to a reinforcement signal. One approach is to recover the expert's cost function with inverse reinforcement learning, then extract a policy from that cost function with reinforcement learning. This approach is indirect and can be slow. We propose a new general framework for directly extracting a policy from data as if it were obtained by reinforcement learning following inverse reinforcement learning. We show that a certain instantiation of our framework draws an analogy between imitation learning and generative adversarial networks, from which we derive a model-free imitation learning algorithm that obtains significant performance gains over existing model-free methods in imitating complex behaviors in large, high-dimensional environments.},
	archivePrefix = {arXiv},
	arxivId = {1606.03476},
	author = {Ho, Jonathan and Ermon, Stefano},
	booktitle = {Advances in Neural Information Processing Systems},
	eprint = {1606.03476},
	issn = {10495258},
	title = {{Generative adversarial imitation learning}},
	year = {2016}
}

@inproceedings{Kuefler2017,
	author={A. {Kuefler} and J. {Morton} and T. {Wheeler} and M. {Kochenderfer}},
	booktitle={2017 IEEE Intelligent Vehicles Symposium (IV)},
	title={Imitating driver behavior with generative adversarial networks},
	year={2017},
	pages={204-211},
}

@article{Bhattacharyya2018,
	author    = {Raunak P. Bhattacharyya and
	Derek J. Phillips and
	Blake Wulfe and
	Jeremy Morton and
	Alex Kuefler and
	Mykel J. Kochenderfer},
	title     = {Multi-Agent Imitation Learning for Driving Simulation},
	journal   = {CoRR},
	volume    = {abs/1803.01044},
	year      = {2018},
	url       = {http://arxiv.org/abs/1803.01044},
	archivePrefix = {arXiv},
	eprint    = {1803.01044},
	timestamp = {Mon, 13 Aug 2018 16:46:17 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1803-01044.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Codevilla2018,
	abstract = {Deep networks trained on demonstrations of human driving have learned to follow roads and avoid obstacles. However, driving policies trained via imitation learning cannot be controlled at test time. A vehicle trained end-to-end to imitate an expert cannot be guided to take a specific turn at an upcoming intersection. This limits the utility of such systems. We propose to condition imitation learning on high-level command input. At test time, the learned driving policy functions as a chauffeur that handles sensorimotor coordination but continues to respond to navigational commands. We evaluate different architectures for conditional imitation learning in vision-based driving. We conduct experiments in realistic three-dimensional simulations of urban driving and on a 1/5 scale robotic truck that is trained to drive in a residential area. Both systems drive based on visual input yet remain responsive to high-level navigational commands.},
	archivePrefix = {arXiv},
	arxivId = {1710.02410},
	author = {Codevilla, Felipe and Miiller, Matthias and Lopez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
	booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
	doi = {10.1109/ICRA.2018.8460487},
	eprint = {1710.02410},
	isbn = {9781538630815},
	issn = {10504729},
	title = {{End-to-End Driving Via Conditional Imitation Learning}},
	year = {2018}
}

@inproceedings{Rhinehart2020,
	title={Deep Imitative Models for Flexible Inference, Planning, and Control},
	author={Nicholas Rhinehart and Rowan McAllister and Sergey Levine},
	year={2020},
	booktitle={International Conference on Learning Representations (ICLR)}
}

@Comment{Chap2_3,
	title =	 {Partial Observability},
}

@misc{ObjCode2017,
	author = {{Editions Nationales du Permis de Conduire}},
	title = {{Objectif Code !}},
	year = {2017}
}

@article{Astrom1965,
	author       = {Åström, Karl Johan},
	issn         = {0022-247X},
	language     = {eng},
	pages        = {174--205},
	publisher    = {Elsevier},
	series       = {Journal of Mathematical Analysis and Applications},
	title        = {Optimal Control of Markov Processes with Incomplete State Information I},
	url          = {https://lup.lub.lu.se/search/ws/files/5323668/8867085.pdf},
	doi          = {10.1016/0022-247X(65)90154-X},
	volume       = {10},
	year         = {1965},
}

@inproceedings{Ulbrich2013,
	abstract = {The Stadtpilot project aims at fully automated driving on Braunschweig's inner city ring road. The TU Braunschweig's research vehicle 'Leonie' is one of the first vehicles having the ability of fully automated driving in real urban traffic scenarios. This paper shows our decision making approach for performing lane changes while driving fully automated in urban environments. We apply an online Partially Observable Markov Decision Process (POMDP) to accommodate inevitable sensor noise to be faced in urban traffic scenarios. In this paper we propose a two step algorithm to keep the complexity of the POMDP low enough for real-time decision making while driving. The presented approach has been integrated in our vehicle and was evaluated in real urban traffic. {\textcopyright} 2013 IEEE.},
	author = {Ulbrich, Simon and Maurer, Markus},
	booktitle = {IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC},
	doi = {10.1109/ITSC.2013.6728533},
	isbn = {9781479929146},
	title = {{Probabilistic online POMDP decision making for lane changes in fully automated driving}},
	year = {2013}
}

@article{Du2010,
	abstract = {Motion planning in uncertain and dynamic environments is critical for reliable operation of autonomous robots. Partially observable Markov decision processes (POMDPs) provide a principled general framework for such planning tasks and have been successfully applied to several moderately complex robotic tasks, including navigation, manipulation, and target tracking. The challenge now is to scale up POMDP planning algorithms and handle more complex, realistic tasks. This paper outlines ideas aimed at overcoming two major obstacles to the efficiency of POMDP planning: the “curse of dimensionality” and the “curse of history”. Our main objective is to show that using these ideas along with others POMDP algorithms can be used successfully for motion planning under uncertainty for robotic tasks with a large number of states or a long time horizon. We implemented some of our algorithms as a software package Ap- proximate POMDP Planning Library (APPL), now available for download at http://motion.comp.nus.edu.sg/ projects/pomdp/pomdp.html. Introduction},
	author = {Du, Yanzhu and Hsu, David and Kurniawati, Hanna and Lee, Wee and Ong, Sylvie and Png, Shao},
	journal = {ICAPS POMDP Practitioners Workshop},
	title = {{A POMDP Approach to Robot Motion Planning Under Uncertainty}},
	year = {2010}
}

@inproceedings{Brechtel2013,
	abstract = {Discrete POMDPs of medium complexity can be approximately solved in reasonable time. However, most applications have a continuous and thus uncountably infinite state space. We propose the novel concept of learning a discrete representation of the continuous state space to solve the integrals in continuous POMDPs efficiently and generalize sparse calculations over the continuous space. The representation is iteratively refined as part of a novel Value Iteration step and does not depend on prior knowledge. Consistency for the learned generalization is asserted by a self-correction algorithm. The presented concept is implemented for continuous state and observation spaces based on Monte Carlo approximation to allow for arbitrary POMDP models. In an experimental comparison it yields higher values in significantly shorter time than state of the art algorithms and solves higher-dimensional problems. Copyright 2013 by the author(s).},
	author = {Brechtel, Sebastian and Gindele, Tobias and Dillmann, R{\"{u}}diger},
	booktitle = {30th International Conference on Machine Learning, ICML 2013},
	title = {{Solving continuous POMDPs: Value iteration with incremental learning of an efficient space representation}},
	year = {2013}
}

@inproceedings{Bouton2018,
	author={M. {Bouton} and A. {Nakhaei} and K. {Fujimura} and M. J. {Kochenderfer}},
	booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, 
	title={Scalable Decision Making with Sensor Occlusions for Autonomous Driving}, 
	year={2018},
	volume={},
	number={},
	pages={2076-2081},
}

@inproceedings{VanDenBerg2011,
	abstract = {In this paper we present LQG-MP (linear-quadratic Gaussian motion planning), a new approach to robot motion planning that takes into account the sensors and the controller that will be used during the execution of the robot's path. LQG-MP is based on the linear-quadratic controller with Gaussian models of uncertainty, and explicitly characterizes in advance (i.e. before execution) the a priori probability distributions of the state of the robot along its path. These distributions can be used to assess the quality of the path, for instance by computing the probability of avoiding collisions. Many methods can be used to generate the required ensemble of candidate paths from which the best path is selected; in this paper we report results using rapidly exploring random trees (RRT). We study the performance of LQG-MP with simulation experiments in three scenarios: (A) a kinodynamic car-like robot, (B) multi-robot planning with differential-drive robots, and (C) a 6-DOF serial manipulator. We also present a method that applies Kalman smoothing to make paths Ck-continuous and apply LQG-MP to precomputed roadmaps using a variant of Dijkstra's algorithm to efficiently find high-quality paths. {\textcopyright} The Author(s) 2011.},
	author = {{Van Den Berg}, Jur and Abbee, Pieter and Goldberg, Ken},
	booktitle = {International Journal of Robotics Research},
	doi = {10.1177/0278364911406562},
	issn = {02783649},
	keywords = {Control,Planning,Uncertainty},
	title = {{LQG-MP: Optimized path planning for robots with motion uncertainty and imperfect state information}},
	year = {2011}
}

@inproceedings{Brechtel2014,
	abstract = {This paper presents a generic approach for tactical decision-making under uncertainty in the context of driving. The complexity of this task mainly stems from the fact that rational decision-making in this context must consider several sources of uncertainty: The temporal evolution of situations cannot be predicted without uncertainty because other road users behave stochastically and their goals and plans cannot be measured. Even more important, road users are only able to perceive a tiny part of the current situation with their sensors because measurements are noisy and most of the environment is occluded. In order to anticipate the consequences of decisions a probabilistic approach, considering both forms of uncertainty, is necessary. We address this by formulating the task of driving as a continuous Partially Observable Markov Decision Process (POMDP) that can be automatically optimized for different scenarios. As driving is a continuous-space problem, the belief space is infinite-dimensional. We do not use a symbolic representation or discretize the state space a priori because there is no representation of the state space that is optimal for every situation. Instead, we employ a continuous POMDP solver that learns a good representation of the specific situation.},
	author = {Brechtel, Sebastian and Gindele, Tobias and Dillmann, Rudiger},
	booktitle = {2014 17th IEEE International Conference on Intelligent Transportation Systems, ITSC 2014},
	doi = {10.1109/ITSC.2014.6957722},
	isbn = {9781479960781},
	title = {{Probabilistic decision-making under uncertainty for autonomous driving using continuous POMDPs}},
	year = {2014}
}

@inproceedings{Bandyopadhyay2013,
	abstract = {As robots venture into new application domains as autonomous vehicles on the road or as domestic helpers at home, they must recognize human intentions and behaviors in order to operate effectively. This paper investigates a new class of motion planning problems with uncertainty in human intention. We propose a method for constructing a practical model by assuming a finite set of unknown intentions. We first construct a motion model for each intention in the set and then combine these models together into a single Mixed Observability Markov Decision Process (MOMDP), which is a structured variant of the more common Partially Observable Markov Decision Process (POMDP). By leveraging the latest advances in POMDP/MOMDP approximation algorithms, we can construct and solve moderately complex models for interesting robotic tasks. Experiments in simulation and with an autonomous vehicle show that the proposed method outperforms common alternatives because of its ability in recognizing intentions and using the information effectively for decision making.},
	author = {Bandyopadhyay, Tirthankar and Won, Kok Sung and Frazzoli, Emilio and Hsu, David and Lee, Wee Sun and Rus, Daniela},
	booktitle = {Springer Tracts in Advanced Robotics},
	doi = {10.1007/978-3-642-36279-8_29},
	isbn = {9783642362781},
	issn = {1610742X},
	title = {{Intention-aware motion planning}},
	year = {2013}
}

@inproceedings{Barbier2018,
	title = {{Probabilistic Decision-Making at Road Intersections: Formulation and Quantitative Evaluation}},
	author = {Barbier, Mathieu and Laugier, Christian and Simonin, Olivier and Iba{\~n}ez-Guzm{\'a}n, Javier},
	url = {https://hal.inria.fr/hal-01940392},
	booktitle = {{ICARCV 2018 - 15 th International Conference on Control, Automation, Robotics and Vision}},
	address = {Singapour, Singapore},
	pages = {1-8},
	year = {2018},
	month = Nov,
	pdf = {https://hal.inria.fr/hal-01940392/file/paper_icarcv_2018_submitted.pdf},
	hal_id = {hal-01940392},
	hal_version = {v1},
}

@inproceedings{Bouton2017,
	abstract = {Urban intersections represent a complex environment for autonomous vehicles with many sources of uncertainty. The vehicle must plan in a stochastic environment with potentially rapid changes in driver behavior. Providing an efficient strategy to navigate through urban intersections is a difficult task. This paper frames the problem of navigating unsignalized intersections as a partially observable Markov decision process (POMDP) and solves it using a Monte Carlo sampling method. Empirical results in simulation show that the resulting policy outperforms a threshold-based heuristic strategy on several relevant metrics that measure both safety and efficiency.},
	archivePrefix = {arXiv},
	arxivId = {1704.04322},
	author = {Bouton, Maxime and Cosgun, Akansel and Kochenderfer, Mykel J.},
	booktitle = {IEEE Intelligent Vehicles Symposium, Proceedings},
	doi = {10.1109/IVS.2017.7995818},
	eprint = {1704.04322},
	isbn = {9781509048045},
	title = {{Belief state planning for autonomously navigating urban intersections}},
	year = {2017}
}


@inproceedings{Sunberg2017,
	abstract = {Safe interaction with human drivers is one of the primary challenges for autonomous vehicles. In order to plan driving maneuvers effectively, the vehicle's control system must infer and predict how humans will behave based on their latent internal state (e.g., intentions and aggressiveness). This research uses a simple model for human behavior with unknown parameters that make up the internal states of the traffic participants and presents a method for quantifying the value of estimating these states and planning with their uncertainty explicitly modeled. An upper performance bound is established by an omniscient Monte Carlo Tree Search (MCTS) planner that has perfect knowledge of the internal states. A baseline lower bound is established by planning with MCTS assuming that all drivers have the same internal state. MCTS variants are then used to solve a partially observable Markov decision process (POMDP) that models the internal state uncertainty to determine whether inferring the internal state offers an advantage over the baseline. Applying this method to a freeway lane changing scenario reveals that there is a significant performance gap between the upper bound and baseline. POMDP planning techniques come close to closing this gap, especially when important hidden model parameters are correlated with measurable parameters.},
	archivePrefix = {arXiv},
	arxivId = {1702.00858},
	author = {Sunberg, Zachary N. and Ho, Christopher J. and Kochenderfer, Mykel J.},
	booktitle = {Proceedings of the American Control Conference},
	doi = {10.23919/ACC.2017.7963408},
	eprint = {1702.00858},
	isbn = {9781509059928},
	issn = {07431619},
	title = {{The value of inferring the internal state of traffic participants for autonomous freeway driving}},
	year = {2017}
}

@inproceedings{Bry2011,
	abstract = {In this paper we address the problem of motion planning in the presence of state uncertainty, also known as planning in belief space. The work is motivated by planning domains involving nontrivial dynamics, spatially varying measurement properties, and obstacle constraints. To make the problem tractable, we restrict the motion plan to a nominal trajectory stabilized with a linear estimator and controller. This allows us to predict distributions over future states given a candidate nominal trajectory. Using these distributions to ensure a bounded probability of collision, the algorithm incrementally constructs a graph of trajectories through state space, while efficiently searching over candidate paths through the graph at each iteration. This process results in a search tree in belief space that provably converges to the optimal path. We analyze the algorithm theoretically and also provide simulation results demonstrating its utility for balancing information gathering to reduce uncertainty and finding low cost paths. {\textcopyright} 2011 IEEE.},
	author = {Bry, Adam and Roy, Nicholas},
	booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
	doi = {10.1109/ICRA.2011.5980508},
	isbn = {9781612843865},
	issn = {10504729},
	title = {{Rapidly-exploring random belief trees for motion planning under uncertainty}},
	year = {2011}
}

@inproceedings{Xu2014,
	abstract = {We present a motion planning framework for autonomous on-road driving considering both the uncertainty caused by an autonomous vehicle and other traffic participants. The future motion of traffic participants is predicted using a local planner, and the uncertainty along the predicted trajectory is computed based on Gaussian propagation. For the autonomous vehicle, the uncertainty from localization and control is estimated based on a Linear-Quadratic Gaussian (LQG) framework. Compared with other safety assessment methods, our framework allows the planner to avoid unsafe situations more efficiently, thanks to the direct uncertainty information feedback to the planner. We also demonstrate our planner's ability to generate safer trajectories compared to planning only with a LQG framework.},
	author = {Xu, Wenda and Pan, Jia and Wei, Junqing and Dolan, John M.},
	booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
	doi = {10.1109/ICRA.2014.6907209},
	issn = {10504729},
	title = {{Motion planning under uncertainty for on-road autonomous driving}},
	year = {2014}
}

@inproceedings{Pineau2003,
	abstract = {This paper introduces the Point-Based Value Iteration (PBVI) algorithm for POMDP planning. PBVI approximates an exact value iteration solution by selecting a small set of representative belief points and then tracking the value and its derivative for those points only. By using stochastic trajectories to choose belief points, and by maintaining only one value hyper-plane per point, PBVI successfully solves large problems: we present results on a robotic laser tag problem as well as three test domains from the literature.},
	author = {Pineau, Joelle and Gordon, Geoff and Thrun, Sebastian},
	booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
	issn = {10450823},
	title = {{Point-based value iteration: An anytime algorithm for POMDPs}},
	year = {2003}
}

@article{Porta2006,
	abstract = {We propose a novel approach to optimize Partially Observable Markov Decisions Processes (POMDPs) defined on continuous spaces. To date, most algorithms for model-based POMDPs are restricted to discrete states, actions, and observations, but many real-world problems such as, for instance, robot navigation, are naturally defined on continuous spaces. In this work, we demonstrate that the value function for continuous POMDPs is convex in the beliefs over continuous state spaces, and piecewise-linear convex for the particular case of discrete observations and actions but still continuous states. We also demonstrate that continuous Bellman backups are contracting and isotonic ensuring the monotonic convergence of value-iteration algorithms. Relying on those properties, we extend the PERSEUS algorithm, originally developed for discrete POMDPs, to work in continuous state spaces by representing the observation, transition, and reward models using Gaussian mixtures, and the beliefs using Gaussian mixtures or particle sets. With these representations, the integrals that appear in the Bellman backup can be computed in closed form and, therefore, the algorithm is computationally feasible. Finally, we further extend PERSEUS to deal with continuous action and observation sets by designing effective sampling approaches.},
	author = {Porta, Josep M. and Vlassis, Nikos and Spaan, Matthijs T.J. and Poupart, Pascal},
	doi = {10.13039/501100000780},
	issn = {15337928},
	journal = {Journal of Machine Learning Research},
	keywords = {Continuous action space,Continuous observation space,Continuous state space,Partially observable Markov decision processes,Planning under uncertainty,Point-based value iteration},
	title = {{Point-based value iteration for continuous POMDPs}},
	year = {2006}
}

@inproceedings{Silver2010,
	abstract = {This paper introduces a Monte-Carlo algorithm for online planning in large POMDPs. The algorithm combines a Monte-Carlo update of the agent's belief state with a Monte-Carlo tree search from the current belief state. The new algorithm, POMCP, has two important properties. First, Monte-Carlo sampling is used to break the curse of dimensionality both during belief state updates and during planning. Second, only a black box simulator of the POMDP is required, rather than explicit probability distributions. These properties enable POMCP to plan effectively in significantly larger POMDPs than has previously been possible. We demonstrate its effectiveness in three large POMDPs. We scale up a well-known benchmark problem, rocksample, by several orders of magnitude. We also introduce two challenging new POMDPs: 10 × 10 battleship and partially observable PacMan, with approximately 10 18 and 10 56 states respectively. Our Monte-Carlo planning algorithm achieved a high level of performance with no prior knowledge, and was also able to exploit simple domain knowledge to achieve better results with less search. POMCP is the first general purpose planner to achieve high performance in such large and unfactored POMDPs.},
	author = {Silver, David and Veness, Joel},
	booktitle = {Advances in Neural Information Processing Systems 23: 24th Annual Conference on Neural Information Processing Systems 2010, NIPS 2010},
	isbn = {9781617823800},
	title = {{Monte-Carlo planning in large POMDPs}},
	year = {2010}
}

@article{Kalman1960,
	abstract = {The classical filtering and prediction problem is re-examined using the Bode-Sliannon representation of random processes and the “state-transition” method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinitememory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the coefficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix. {\textcopyright} 1960 by ASME.},
	author = {Kalman, R. E.},
	doi = {10.1115/1.3662552},
	issn = {1528901X},
	journal = {Journal of Fluids Engineering, Transactions of the ASME},
	title = {{A new approach to linear filtering and prediction problems}},
	year = {1960}
}

@inproceedings{VanDenBerg2017,
	abstract = {We present an approach to motion planning under motion and sensing un-certainty, formally described as a continuous partially-observable Markov decision process (POMDP). Our approach is designed for non-linear dynamics and observation models, and follows the general POMDP solution framework in which we represent beliefs by Gaussian distributions, approximate the belief dynamics using an extended Kalman filter (EKF), and represent the value function by a quadratic function that is valid in the vicinity of a nominal trajectory through belief space. Using a variant of differential dynamic programming, our approach iterates with second-order convergence towards a linear control policy over the belief space that is locally-optimal with respect to a user-defined cost function. Unlike previous work, our approach does not assume maximum-likelihood observations, does not assume fixed estimator or control gains, takes into account obstacles in the environment, and does not require discretization of the belief space. The running time of the algorithm is polynomial in the dimension of the state space. We demonstrate the potential of our approach in several continuous partially-observable planning domains with obstacles for robots with non-linear dynamics and observation models.},
	author = {{Van Den Berg}, Jur and Patil, Sachin and Alterovitz, Ron},
	booktitle = {Springer Tracts in Advanced Robotics},
	doi = {10.1007/978-3-319-29363-9_27},
	isbn = {9783319293622},
	issn = {1610742X},
	title = {{Motion planning under uncertainty using differential dynamic programming in belief space}},
	year = {2017}
}

@inproceedings{Brechtel2011,
	abstract = {This paper presents a method for high-level decision making in traffic environments. In contrast to the usual approach of modeling decision policies by hand, a Markov Decision Process (MDP) is employed to plan the optimal policy by assessing the outcomes of actions. Using probability theory, decisions are deduced automatically from the knowledge about how road users behave over time. This approach does neither depend on an explicit situation recognition nor is it limited to only a variety of situations or types of descriptions. Hence it is versatile and powerful. The contribution of this paper is a mathematical framework to derive abstract symbolic states from complex continuous temporal models encoded as Dynamic Bayesian Networks (DBN). For this purpose discrete MDP states are interpreted by random variables. To make computation feasible this space grows adaptively during planning and according to the problem to be solved. {\textcopyright} 2011 IEEE.},
	author = {Brechtel, Sebastian and Gindele, Tobias and Dillmann, Rudiger},
	booktitle = {IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC},
	doi = {10.1109/ITSC.2011.6082928},
	isbn = {9781457721984},
	title = {{Probabilistic MDP-behavior planning for cars}},
	year = {2011}
}

@inproceedings{Sun2019,
	abstract = {Autonomous cars have to navigate in dynamic environment which can be full of uncertainties. The uncertainties can come either from sensor limitations such as occlusions and limited sensor range, or from probabilistic prediction of other road participants, or from unknown social behavior in a new area. To safely and efficiently drive in the presence of these uncertainties, the decision-making and planning modules of autonomous cars should intelligently utilize all available information and appropriately tackle the uncertainties so that proper driving strategies can be generated. In this paper, we propose a social perception scheme which treats all road participants as distributed sensors in a sensor network. By observing the individual behaviors as well as the group behaviors, uncertainties of the three types can be updated uniformly in a belief space. The updated beliefs from the social perception are then explicitly incorporated into a probabilistic planning framework based on Model Predictive Control (MPC). The cost function of the MPC is learned via inverse reinforcement learning (IRL). Such an integrated probabilistic planning module with socially enhanced perception enables the autonomous vehicles to generate behaviors which are defensive but not overly conservative, and socially compatible. The effectiveness of the proposed framework is verified in simulation on an representative scenario with sensor occlusions.},
	archivePrefix = {arXiv},
	arxivId = {1905.00988},
	author = {Sun, Liting and Zhan, Wei and Chan, Ching Yao and Tomizuka, Masayoshi},
	booktitle = {IEEE Intelligent Vehicles Symposium, Proceedings},
	doi = {10.1109/IVS.2019.8814223},
	eprint = {1905.00988},
	isbn = {9781728105604},
	title = {{Behavior planning of autonomous cars with social perception}},
	year = {2019}
}

@Comment{Chap2_4,
	title =	 {Inverse Reinforcement Learning},
}

@inproceedings{Sadigh2016,
	abstract = {Traditionally, autonomous cars make predictions about other drivers' future trajectories, and plan to stay out of their way. This tends to result in defensive and opaque behaviors. Our key insight is that an autonomous car's actions will actually affect what other cars will do in response, whether the car is aware of it or not. Our thesis is that we can leverage these responses to plan more efficient and communicative behaviors. We model the interaction between an autonomous car and a human driver as a dynamical system, in which the robot's actions have immediate consequences on the state of the car, but also on human actions. We model these consequences by approximating the human as an optimal planner, with a reward function that we acquire through Inverse Reinforcement Learning. When the robot plans with this reward function in this dynamical system, it comes up with actions that purposefully change human state: it merges in front of a human to get them to slow down or to reach its own goal faster; it blocks two lanes to get them to switch to a third lane; or it backs up slightly at an intersection to get them to proceed first. Such behaviors arise from the optimization, without relying on hand-coded signaling strategies and without ever explicitly modeling communication. Our user study results suggest that the robot is indeed capable of eliciting desired changes in human state by planning using this dynamical system.},
	author = {Sadigh, Dorsa and Sastry, Shankar and Seshia, Sanjit A. and Dragan, Anca D.},
	booktitle = {Robotics: Science and Systems},
	doi = {10.15607/rss.2016.xii.029},
	isbn = {9780992374723},
	issn = {2330765X},
	title = {{Planning for autonomous cars that leverage effects on human actions}},
	year = {2016}
}
